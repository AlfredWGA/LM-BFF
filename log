{'time': '2021-05-19 07:51:24.568444', 'eprstmt_dev_eval_loss': 2.034740447998047, 'eprstmt_dev_eval_acc': 0.78125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-3315', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May19_07-47-50_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-3315', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/eprstmt/16-13', 'max_seq_length': 270, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/eprstmt/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-19 07:52:57.911833', 'eprstmt_dev_eval_loss': 2.034740447998047, 'eprstmt_dev_eval_acc': 0.78125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-23687', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May19_07-51-28_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-23687', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/eprstmt/16-13', 'max_seq_length': 270, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/eprstmt/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 1, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-19 07:54:33.825519', 'eprstmt_dev_eval_loss': 2.014031410217285, 'eprstmt_dev_eval_acc': 0.84375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-25222', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May19_07-53-02_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-25222', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/eprstmt/16-13', 'max_seq_length': 270, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask*。*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/eprstmt/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 2, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-19 07:56:08.502205', 'eprstmt_dev_eval_loss': 2.255415201187134, 'eprstmt_dev_eval_acc': 0.75, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-28551', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May19_07-54-37_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-28551', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/eprstmt/16-13', 'max_seq_length': 270, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask*的*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/eprstmt/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 3, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-19 07:57:42.300265', 'eprstmt_dev_eval_loss': 2.6631550788879395, 'eprstmt_dev_eval_acc': 0.78125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-12778', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May19_07-56-12_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-12778', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/eprstmt/16-13', 'max_seq_length': 270, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*太*mask*了*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/eprstmt/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 4, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-19 07:59:15.360316', 'eprstmt_dev_eval_loss': 2.1370978355407715, 'eprstmt_dev_eval_acc': 0.84375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-32754', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May19_07-57-46_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-32754', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/eprstmt/16-13', 'max_seq_length': 270, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask*啊*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/eprstmt/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 5, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-19 08:00:49.413988', 'eprstmt_dev_eval_loss': 2.5529417991638184, 'eprstmt_dev_eval_acc': 0.75, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-1292', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May19_07-59-19_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-1292', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/eprstmt/16-13', 'max_seq_length': 270, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*就*mask*了*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/eprstmt/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 6, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-19 08:02:20.913314', 'eprstmt_dev_eval_loss': 2.4328362941741943, 'eprstmt_dev_eval_acc': 0.75, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-27615', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May19_08-00-53_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-27615', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/eprstmt/16-13', 'max_seq_length': 270, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*还*mask**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/eprstmt/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 7, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-19 08:03:53.275738', 'eprstmt_dev_eval_loss': 2.034740447998047, 'eprstmt_dev_eval_acc': 0.78125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-910', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May19_08-02-25_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-910', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/eprstmt/16-13', 'max_seq_length': 270, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/eprstmt/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 8, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-19 08:05:28.034429', 'eprstmt_dev_eval_loss': 2.014031410217285, 'eprstmt_dev_eval_acc': 0.84375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-31333', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May19_08-03-57_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-31333', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/eprstmt/16-13', 'max_seq_length': 270, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask*。*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/eprstmt/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 9, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-19 08:06:59.826012', 'eprstmt_dev_eval_loss': 2.255415201187134, 'eprstmt_dev_eval_acc': 0.75, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-6676', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May19_08-05-32_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-6676', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/eprstmt/16-13', 'max_seq_length': 270, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask*的*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/eprstmt/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 10, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-19 08:08:31.594972', 'eprstmt_dev_eval_loss': 2.6631550788879395, 'eprstmt_dev_eval_acc': 0.78125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-20040', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May19_08-07-03_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-20040', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/eprstmt/16-13', 'max_seq_length': 270, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*太*mask*了*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/eprstmt/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 11, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-19 08:10:03.884232', 'eprstmt_dev_eval_loss': 2.1370978355407715, 'eprstmt_dev_eval_acc': 0.84375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-25838', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May19_08-08-35_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-25838', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/eprstmt/16-13', 'max_seq_length': 270, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask*啊*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/eprstmt/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 12, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-19 08:11:36.053053', 'eprstmt_dev_eval_loss': 2.034740447998047, 'eprstmt_dev_eval_acc': 0.78125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-1643', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May19_08-10-08_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-1643', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/eprstmt/16-13', 'max_seq_length': 270, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/eprstmt/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 13, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-19 08:13:07.378433', 'eprstmt_dev_eval_loss': 2.255415201187134, 'eprstmt_dev_eval_acc': 0.75, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-3855', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May19_08-11-40_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-3855', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/eprstmt/16-13', 'max_seq_length': 270, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask*的*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/eprstmt/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 14, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-19 08:14:39.100117', 'eprstmt_dev_eval_loss': 1.4091157913208008, 'eprstmt_dev_eval_acc': 0.8125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-12289', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May19_08-13-11_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-12289', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/eprstmt/16-13', 'max_seq_length': 270, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*，*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/eprstmt/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 15, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-19 08:16:11.691858', 'eprstmt_dev_eval_loss': 1.4091157913208008, 'eprstmt_dev_eval_acc': 0.8125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-19884', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May19_08-14-43_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-19884', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/eprstmt/16-13', 'max_seq_length': 270, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*，*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/eprstmt/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 16, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-19 08:17:43.247826', 'eprstmt_dev_eval_loss': 1.4091157913208008, 'eprstmt_dev_eval_acc': 0.8125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-3372', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May19_08-16-15_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-3372', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/eprstmt/16-13', 'max_seq_length': 270, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*，*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/eprstmt/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 17, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-19 08:19:15.516875', 'eprstmt_dev_eval_loss': 1.4091157913208008, 'eprstmt_dev_eval_acc': 0.8125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-28089', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May19_08-17-47_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-28089', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/eprstmt/16-13', 'max_seq_length': 270, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*，*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/eprstmt/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 18, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-19 08:20:47.107168', 'eprstmt_dev_eval_loss': 2.0221879482269287, 'eprstmt_dev_eval_acc': 0.6875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-16329', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May19_08-19-19_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-16329', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/eprstmt/16-13', 'max_seq_length': 270, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*的*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/eprstmt/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 19, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-19 08:22:18.999343', 'eprstmt_dev_eval_loss': 2.0221879482269287, 'eprstmt_dev_eval_acc': 0.6875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-21799', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May19_08-20-51_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-21799', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/eprstmt/16-13', 'max_seq_length': 270, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*的*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/eprstmt/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 20, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-19 08:23:50.873909', 'eprstmt_dev_eval_loss': 1.4091157913208008, 'eprstmt_dev_eval_acc': 0.8125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-31128', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May19_08-22-23_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-31128', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/eprstmt/16-13', 'max_seq_length': 270, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*，*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/eprstmt/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 21, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-19 08:25:21.012361', 'eprstmt_dev_eval_loss': 1.4091157913208008, 'eprstmt_dev_eval_acc': 0.8125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-28142', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May19_08-23-54_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-28142', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/eprstmt/16-13', 'max_seq_length': 270, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*，*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/eprstmt/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 22, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-19 08:26:52.466909', 'eprstmt_dev_eval_loss': 1.4091157913208008, 'eprstmt_dev_eval_acc': 0.8125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-14451', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May19_08-25-25_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-14451', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/eprstmt/16-13', 'max_seq_length': 270, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*，*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/eprstmt/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 23, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-19 08:28:24.337941', 'eprstmt_dev_eval_loss': 2.0221879482269287, 'eprstmt_dev_eval_acc': 0.6875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-15480', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May19_08-26-56_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-15480', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/eprstmt/16-13', 'max_seq_length': 270, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*的*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/eprstmt/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 24, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-19 08:29:55.107799', 'eprstmt_dev_eval_loss': 1.5992485284805298, 'eprstmt_dev_eval_acc': 0.8125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-10442', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May19_08-28-28_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-10442', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/eprstmt/16-13', 'max_seq_length': 270, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*。*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/eprstmt/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 25, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-19 08:31:26.057205', 'eprstmt_dev_eval_loss': 1.4091157913208008, 'eprstmt_dev_eval_acc': 0.8125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-8075', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May19_08-29-59_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-8075', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/eprstmt/16-13', 'max_seq_length': 270, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*，*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/eprstmt/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 26, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-19 08:32:58.462174', 'eprstmt_dev_eval_loss': 1.4091157913208008, 'eprstmt_dev_eval_acc': 0.8125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-29245', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May19_08-31-30_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-29245', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/eprstmt/16-13', 'max_seq_length': 270, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*，*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/eprstmt/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 27, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-19 08:34:29.497543', 'eprstmt_dev_eval_loss': 2.0221879482269287, 'eprstmt_dev_eval_acc': 0.6875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-2497', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May19_08-33-02_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-2497', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/eprstmt/16-13', 'max_seq_length': 270, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*的*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/eprstmt/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 28, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-19 08:35:59.819175', 'eprstmt_dev_eval_loss': 2.5297818183898926, 'eprstmt_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-29601', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May19_08-34-33_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt--13-hfl/chinese-roberta-wwm-ext-29601', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/eprstmt/16-13', 'max_seq_length': 270, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*蛮*mask*的*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/eprstmt/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 29, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-19 18:22:44.315985', 'eprstmt_dev_eval_loss': 2.778935194015503, 'eprstmt_dev_eval_acc': 0.75, 'eprstmt_test_eval_loss': 1.4303438663482666, 'eprstmt_test_eval_acc': 0.7983606557377049, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt-demo', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-demo-16-13-hfl/chinese-roberta-wwm-ext-13011', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/May19_18-17-12_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-demo-16-13-hfl/chinese-roberta-wwm-ext-13011', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/eprstmt/16-13', 'max_seq_length': 128, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask*。*sep+**sent_1*很*label_0*。*sep+**sent_2*很*label_1*。*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/eprstmt/16-13.sort.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': '', 'demo_filter': True, 'demo_filter_rate': 0.5, 'demo_filter_model': 'sbert-distiluse-base-multilingual-cased-v1', 'debug_mode': False, 'double_demo': True, 'first_sent_limit': 128, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-19 18:37:03.534074', 'eprstmt_dev_eval_loss': 2.9098293781280518, 'eprstmt_dev_eval_acc': 0.71875, 'eprstmt_test_eval_loss': 1.4044560194015503, 'eprstmt_test_eval_acc': 0.8278688524590164, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt-demo', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-demo-16-13-hfl/chinese-roberta-wwm-ext-16982', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/May19_18-29-47_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-demo-16-13-hfl/chinese-roberta-wwm-ext-16982', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/eprstmt/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask*。*sep+**sent_1*很*label_0*。*sep+**sent_2*很*label_1*。*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/eprstmt/16-13.sort.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': '', 'demo_filter': True, 'demo_filter_rate': 0.5, 'demo_filter_model': 'sbert-distiluse-base-multilingual-cased-v1', 'debug_mode': False, 'double_demo': True, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-19 18:52:59.884379', 'eprstmt_dev_eval_loss': 2.0884227752685547, 'eprstmt_dev_eval_acc': 0.84375, 'eprstmt_test_eval_loss': 1.2427093982696533, 'eprstmt_test_eval_acc': 0.8311475409836065, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-16-13-hfl/chinese-roberta-wwm-ext-17890', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/May19_18-48-34_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-16-13-hfl/chinese-roberta-wwm-ext-17890', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/eprstmt/16-13', 'max_seq_length': 270, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask*。*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/eprstmt/16-13.sort.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': '', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 00:55:32.118354', 'tnews_dev_eval_loss': 3.0540659427642822, 'tnews_dev_eval_acc': 0.5833333333333334, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-25882', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_00-53-55_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-25882', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent_0*_-_*mask*讯网*sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 00:57:09.636347', 'tnews_dev_eval_loss': 1.6289228200912476, 'tnews_dev_eval_acc': 0.575, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4897', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_00-55-37_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4897', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent_0*_-_*mask*信网*sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 1, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 00:58:48.600589', 'tnews_dev_eval_loss': 1.848554253578186, 'tnews_dev_eval_acc': 0.5541666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-27652', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_00-57-14_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-27652', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent_0*_-_*mask*_网*sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 2, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 01:00:32.280663', 'tnews_dev_eval_loss': 2.878983497619629, 'tnews_dev_eval_acc': 0.5708333333333333, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-3306', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_00-58-52_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-3306', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent_0*_-_*mask*中网*sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 3, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 01:02:16.529969', 'tnews_dev_eval_loss': 2.8601908683776855, 'tnews_dev_eval_acc': 0.575, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4906', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_01-00-36_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4906', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent_0*_-_*mask*人网*sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 4, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 01:03:55.532212', 'tnews_dev_eval_loss': 2.9802231788635254, 'tnews_dev_eval_acc': 0.5583333333333333, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-26874', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_01-02-20_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-26874', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent_0*_-_*mask*家网*sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 5, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 01:05:35.695643', 'tnews_dev_eval_loss': 1.6451690196990967, 'tnews_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-1174', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_01-03-59_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-1174', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent_0*_-_*mask*都网*sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 6, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 01:07:19.441825', 'tnews_dev_eval_loss': 3.1186559200286865, 'tnews_dev_eval_acc': 0.5666666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-6323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_01-05-40_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-6323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent_0*_-_*mask*友网*sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 7, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 01:09:03.590938', 'tnews_dev_eval_loss': 2.8287553787231445, 'tnews_dev_eval_acc': 0.5708333333333333, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-8218', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_01-07-24_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-8218', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent_0*_-_*mask*民网*sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 8, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 01:10:45.642924', 'tnews_dev_eval_loss': 3.0070042610168457, 'tnews_dev_eval_acc': 0.5541666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-16185', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_01-09-07_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-16185', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent_0*_-_*mask*商网*sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 9, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 01:12:21.896966', 'tnews_dev_eval_loss': 1.6284050941467285, 'tnews_dev_eval_acc': 0.5583333333333333, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-14756', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_01-10-49_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-14756', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent_0*_-_*mask*博网*sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 10, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 01:14:03.462680', 'tnews_dev_eval_loss': 2.472221851348877, 'tnews_dev_eval_acc': 0.5875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-23698', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_01-12-26_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-23698', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent_0*_-_*mask*通网*sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 11, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 01:15:41.137931', 'tnews_dev_eval_loss': 1.7076184749603271, 'tnews_dev_eval_acc': 0.55, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-13257', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_01-14-08_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-13257', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent_0*_-_*mask*城新闻网*sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 12, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 01:17:24.106747', 'tnews_dev_eval_loss': 3.0610415935516357, 'tnews_dev_eval_acc': 0.5583333333333333, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-27611', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_01-15-45_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-27611', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent_0*_-_*mask*报网*sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 13, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 01:19:04.483882', 'tnews_dev_eval_loss': 2.8769822120666504, 'tnews_dev_eval_acc': 0.5833333333333334, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-12341', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_01-17-28_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-12341', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent_0*_-_*mask*文网*sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 14, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 01:20:44.173152', 'tnews_dev_eval_loss': 3.1677281856536865, 'tnews_dev_eval_acc': 0.5458333333333333, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-9749', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_01-19-08_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-9749', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls*com_*mask*..._*+sent_0**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 15, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 01:22:22.019793', 'tnews_dev_eval_loss': 1.6847519874572754, 'tnews_dev_eval_acc': 0.5291666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-12888', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_01-20-48_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-12888', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls*com_*mask*讯_*+sent_0**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 16, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 01:24:01.896785', 'tnews_dev_eval_loss': 3.058572292327881, 'tnews_dev_eval_acc': 0.5291666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-24071', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_01-22-26_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-24071', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls*com_*mask*网_*+sent_0**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 17, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 01:25:40.900970', 'tnews_dev_eval_loss': 1.6099644899368286, 'tnews_dev_eval_acc': 0.5125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-11524', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_01-24-07_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-11524', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls*com_*mask*。_*+sent_0**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 18, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 01:27:21.156254', 'tnews_dev_eval_loss': 2.727329730987549, 'tnews_dev_eval_acc': 0.525, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-382', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_01-25-45_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-382', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls*com_*mask*._*+sent_0**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 19, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 01:29:01.653005', 'tnews_dev_eval_loss': 2.7598023414611816, 'tnews_dev_eval_acc': 0.5666666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-2225', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_01-27-24_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-2225', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls*com_*mask*讯:_*+sent_0**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 20, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 01:30:40.579139', 'tnews_dev_eval_loss': 2.704322338104248, 'tnews_dev_eval_acc': 0.5583333333333333, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-19886', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_01-29-04_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-19886', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls*com_*mask*_-_*+sent_0**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 21, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 01:32:18.806109', 'tnews_dev_eval_loss': 2.7177505493164062, 'tnews_dev_eval_acc': 0.5291666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-25060', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_01-30-43_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-25060', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls*com_*mask*信_*+sent_0**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 22, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 01:33:56.724478', 'tnews_dev_eval_loss': 2.6633458137512207, 'tnews_dev_eval_acc': 0.5166666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-261', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_01-32-22_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-261', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls*com_*mask*中_*+sent_0**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 23, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 01:35:34.399810', 'tnews_dev_eval_loss': 1.6396410465240479, 'tnews_dev_eval_acc': 0.5375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-1325', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_01-34-01_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-1325', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls*com_*mask*情_*+sent_0**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 24, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 01:37:14.477101', 'tnews_dev_eval_loss': 2.9476990699768066, 'tnews_dev_eval_acc': 0.5125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-23164', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_01-35-39_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-23164', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls*com_*mask*大_*+sent_0**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 25, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 01:38:50.425538', 'tnews_dev_eval_loss': 1.6778188943862915, 'tnews_dev_eval_acc': 0.5458333333333333, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-2464', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_01-37-19_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-2464', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls*com_*mask*文_*+sent_0**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 26, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 01:40:28.165151', 'tnews_dev_eval_loss': 1.5861318111419678, 'tnews_dev_eval_acc': 0.5166666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-7773', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_01-38-54_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-7773', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls*com.cn_*mask*..._*+sent_0**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 27, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 01:42:05.890980', 'tnews_dev_eval_loss': 1.6041685342788696, 'tnews_dev_eval_acc': 0.5458333333333333, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-138', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_01-40-32_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-138', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls*com_*mask*信网_*+sent_0**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 28, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 01:43:48.438474', 'tnews_dev_eval_loss': 2.542224645614624, 'tnews_dev_eval_acc': 0.525, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-2016', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_01-42-11_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-2016', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls*com_*mask*博_*+sent_0**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 29, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 02:25:12.633340', 'tnews_dev_eval_loss': 3.645430088043213, 'tnews_dev_eval_acc': 0.5875, 'tnews_test_eval_loss': 3.6916682720184326, 'tnews_test_eval_acc': 0.573134328358209, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-16-13-hfl/chinese-roberta-wwm-ext-28485', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/May24_02-20-42_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-16-13-hfl/chinese-roberta-wwm-ext-28485', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent_0*_-_*mask*通网*sep+*', 'mapping': "{100:'事',101:'文',102:'娱',103:'体',104:'财',106:'房',107:'车',108:'教',109:'科',110:'军',112:'旅',113:'国',114:'股',115:'农',116:'游'}", 'template_path': 'my_auto_template/tnews/16-13.sort.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': '', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 07:10:06.195492', 'tnews_dev_eval_loss': 1.5565956830978394, 'tnews_dev_eval_acc': 0.5375, 'tnews_test_eval_loss': 1.689652919769287, 'tnews_test_eval_acc': 0.545273631840796, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt-demo', 'random_segment': False, 'output_dir': 'result/tnews-prompt-demo-16-13-hfl/chinese-roberta-wwm-ext-8466', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/May24_06-53-43_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-demo-16-13-hfl/chinese-roberta-wwm-ext-8466', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent_0*_-_*mask*通网*sep+*_*sent_1*_-_*label_0*通网*sep+*_*sent_2*_-_*label_1*通网*sep+*_*sent_3*_-_*label_2*通网*sep+*_*sent_4*_-_*label_3*通网*sep+*_*sent_5*_-_*label_4*通网*sep+*_*sent_6*_-_*label_5*通网*sep+*_*sent_7*_-_*label_6*通网*sep+*_*sent_8*_-_*label_7*通网*sep+*_*sent_9*_-_*label_8*通网*sep+*_*sent_10*_-_*label_9*通网*sep+*_*sent_11*_-_*label_10*通网*sep+*_*sent_12*_-_*label_11*通网*sep+*_*sent_13*_-_*label_12*通网*sep+*_*sent_14*_-_*label_13*通网*sep+*_*sent_15*_-_*label_14*通网*sep+*', 'mapping': "{100:'事',101:'文',102:'娱',103:'体',104:'财',106:'房',107:'车',108:'教',109:'科',110:'军',112:'旅',113:'国',114:'股',115:'农',116:'游'}", 'template_path': 'my_auto_template/tnews/16-13.sort.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': '', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': True, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 07:39:56.472381', 'ocnli_dev_eval_loss': 2.6437835693359375, 'ocnli_dev_eval_acc': 0.375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-20051', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_07-38-29_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-20051', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent-_0*。_*mask*说_*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 07:41:20.880943', 'ocnli_dev_eval_loss': 2.423769950866699, 'ocnli_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-17572', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_07-39-58_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-17572', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent-_0*。_*mask*,_*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 1, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 07:42:45.142823', 'ocnli_dev_eval_loss': 2.702624797821045, 'ocnli_dev_eval_acc': 0.40625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-1948', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_07-41-23_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-1948', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent-_0*,_*mask*说_*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 2, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 07:44:09.268991', 'ocnli_dev_eval_loss': 2.0656261444091797, 'ocnli_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-14558', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_07-42-47_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-14558', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent-_0*。_*mask*成_*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 3, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 07:45:32.792073', 'ocnli_dev_eval_loss': 2.069359302520752, 'ocnli_dev_eval_acc': 0.375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-10655', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_07-44-11_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-10655', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent-_0*。_*mask*不_*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 4, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 07:46:58.022908', 'ocnli_dev_eval_loss': 3.0906505584716797, 'ocnli_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-17361', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_07-45-35_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-17361', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent-_0*。_*mask*说,_*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 5, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 07:48:24.194134', 'ocnli_dev_eval_loss': 3.3926243782043457, 'ocnli_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-27006', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_07-47-00_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-27006', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent-_0*。_*mask*这样_*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 6, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 07:49:47.254873', 'ocnli_dev_eval_loss': 1.914099097251892, 'ocnli_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-21581', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_07-48-26_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-21581', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent-_0*,_*mask*成_*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 7, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 07:51:09.741026', 'ocnli_dev_eval_loss': 2.4278454780578613, 'ocnli_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-4611', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_07-49-49_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-4611', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent-_0*。_*mask*让_*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 8, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 07:52:32.546556', 'ocnli_dev_eval_loss': 2.6300411224365234, 'ocnli_dev_eval_acc': 0.375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-11212', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_07-51-11_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-11212', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent-_0*。_*mask*怕_*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 9, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 07:53:58.305466', 'ocnli_dev_eval_loss': 2.6437835693359375, 'ocnli_dev_eval_acc': 0.375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-2824', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_07-52-34_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-2824', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent-_0*_。_*mask*说_*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 10, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 07:55:21.586098', 'ocnli_dev_eval_loss': 3.295713424682617, 'ocnli_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-23004', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_07-54-00_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-23004', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent-_0*。_*mask*这样,_*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 11, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 07:56:46.624124', 'ocnli_dev_eval_loss': 2.1934757232666016, 'ocnli_dev_eval_acc': 0.40625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-13820', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_07-55-23_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-13820', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent-_0*。_*mask*多_*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 12, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 07:58:14.474843', 'ocnli_dev_eval_loss': 2.2144505977630615, 'ocnli_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18921', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_07-56-48_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18921', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent-_0*。_*mask*看_*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 13, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 07:59:37.105052', 'ocnli_dev_eval_loss': 2.069359302520752, 'ocnli_dev_eval_acc': 0.375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-8176', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_07-58-16_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-8176', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent-_0*。_*mask*_不_*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 14, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 08:01:00.660050', 'ocnli_dev_eval_loss': 3.762834072113037, 'ocnli_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-24199', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_07-59-39_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-24199', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent-_0*。_*mask*多说_*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 15, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 08:02:25.263646', 'ocnli_dev_eval_loss': 2.622357130050659, 'ocnli_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-11894', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_08-01-02_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-11894', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent-_0*。_*mask*为_*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 16, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 08:03:48.797826', 'ocnli_dev_eval_loss': 3.923015594482422, 'ocnli_dev_eval_acc': 0.34375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-17682', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_08-02-27_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-17682', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent-_0*。_*mask*说:_*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 17, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 08:05:12.810010', 'ocnli_dev_eval_loss': 2.423769950866699, 'ocnli_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-16050', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_08-03-50_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-16050', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent-_0*。_*mask*_,_*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 18, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 08:06:37.730845', 'ocnli_dev_eval_loss': 3.5560803413391113, 'ocnli_dev_eval_acc': 0.34375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-12618', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_08-05-15_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-12618', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent-_0*,_*mask*说,_*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 19, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 08:08:01.926842', 'ocnli_dev_eval_loss': 2.423769950866699, 'ocnli_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-1498', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_08-06-39_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-1498', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent-_0*_。_*mask*,_*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 20, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 08:09:25.834645', 'ocnli_dev_eval_loss': 2.2043826580047607, 'ocnli_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-22815', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_08-08-04_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-22815', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent-_0*。_*mask*_是_*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 21, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 08:10:50.112027', 'ocnli_dev_eval_loss': 2.0030417442321777, 'ocnli_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-14567', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_08-09-27_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-14567', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent-_0*,_*mask*_不_*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 22, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 08:12:18.911163', 'ocnli_dev_eval_loss': 3.725893974304199, 'ocnli_dev_eval_acc': 0.40625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-26063', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_08-10-52_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-26063', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent-_0*。_*mask*多说,_*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 23, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 08:13:41.369072', 'ocnli_dev_eval_loss': 2.0656261444091797, 'ocnli_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-7581', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_08-12-21_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-7581', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent-_0*_。_*mask*成_*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 24, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 08:15:06.674777', 'ocnli_dev_eval_loss': 3.0906505584716797, 'ocnli_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-14000', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_08-13-43_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-14000', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent-_0*_。_*mask*说,_*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 25, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 08:16:29.543671', 'ocnli_dev_eval_loss': 4.066596984863281, 'ocnli_dev_eval_acc': 0.375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-25288', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_08-15-08_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-25288', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent-_0*。_*mask*为人知_*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 26, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 08:17:52.759115', 'ocnli_dev_eval_loss': 2.069359302520752, 'ocnli_dev_eval_acc': 0.375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-28484', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_08-16-31_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-28484', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent-_0*_。_*mask*_不_*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 27, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 08:19:16.890834', 'ocnli_dev_eval_loss': 2.753084659576416, 'ocnli_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-22890', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_08-17-54_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-22890', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent-_0*。_*mask*_不_,_*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 28, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 08:20:39.465103', 'ocnli_dev_eval_loss': 3.6993870735168457, 'ocnli_dev_eval_acc': 0.34375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-21421', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_08-19-18_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-21421', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent-_0*。_*mask*_不_不_*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 29, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 16:13:07.138330', 'ocnli_dev_eval_loss': 2.3411009311676025, 'ocnli_dev_eval_acc': 0.59375, 'ocnli_test_eval_loss': 2.920542001724243, 'ocnli_test_eval_acc': 0.4170634920634921, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-16-13-hfl/chinese-roberta-wwm-ext-14319', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/May24_16-09-14_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-16-13-hfl/chinese-roberta-wwm-ext-14319', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '_*cls**sent-_0*。_*mask*,_*+sentl_1**sep+*', 'mapping': "{'contradiction':'不','neutral':'或','entailment':'是'}", 'template_path': 'my_auto_template/ocnli/16-13.sort.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': '', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 17:39:33.827800', 'ocnli_dev_eval_loss': 2.1712751388549805, 'ocnli_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-11225', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_17-38-06_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-11225', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*的*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 17:40:59.934808', 'ocnli_dev_eval_loss': 2.518157958984375, 'ocnli_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-14710', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_17-39-35_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-14710', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*，*mask*说*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 1, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 17:42:24.525008', 'ocnli_dev_eval_loss': 2.481074094772339, 'ocnli_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-2696', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_17-41-02_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-2696', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*，*mask*，*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 2, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 17:43:48.520525', 'ocnli_dev_eval_loss': 2.2387781143188477, 'ocnli_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-31792', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_17-42-26_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-31792', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*，*mask**+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 3, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 17:45:12.186579', 'ocnli_dev_eval_loss': 2.679225444793701, 'ocnli_dev_eval_acc': 0.3125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-23383', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_17-43-50_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-23383', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0**mask*说*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 4, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 17:46:36.816197', 'ocnli_dev_eval_loss': 2.491194009780884, 'ocnli_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18179', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_17-45-14_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18179', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask**+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 5, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 17:48:01.450606', 'ocnli_dev_eval_loss': 2.6422677040100098, 'ocnli_dev_eval_acc': 0.25, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-16108', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_17-46-39_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-16108', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0**mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 6, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 17:49:24.909857', 'ocnli_dev_eval_loss': 1.994215488433838, 'ocnli_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-32025', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_17-48-03_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-32025', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 7, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 17:50:49.580672', 'ocnli_dev_eval_loss': 2.2286925315856934, 'ocnli_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-1649', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_17-49-27_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-1649', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*，*mask*的*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 8, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 17:52:17.361843', 'ocnli_dev_eval_loss': 3.081838607788086, 'ocnli_dev_eval_acc': 0.34375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-31379', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_17-50-51_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-31379', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*也*mask*说*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 9, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 17:53:39.514093', 'ocnli_dev_eval_loss': 2.388972282409668, 'ocnli_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-20440', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_17-52-19_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-20440', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*，*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 10, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 17:55:01.994693', 'ocnli_dev_eval_loss': 2.5446839332580566, 'ocnli_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-28367', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_17-53-41_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-28367', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*。*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 11, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 17:56:24.445307', 'ocnli_dev_eval_loss': 2.5201075077056885, 'ocnli_dev_eval_acc': 0.25, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-30636', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_17-55-04_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-30636', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0**mask*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 12, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 17:57:48.712853', 'ocnli_dev_eval_loss': 2.9628114700317383, 'ocnli_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-20887', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_17-56-26_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-20887', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*，*mask*者*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 13, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 17:59:11.772321', 'ocnli_dev_eval_loss': 2.0115785598754883, 'ocnli_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-14327', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_17-57-50_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-14327', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*，*mask*让*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 14, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 18:00:39.956808', 'ocnli_dev_eval_loss': 2.4476404190063477, 'ocnli_dev_eval_acc': 0.40625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-25958', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_17-59-14_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-25958', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*说*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 15, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 18:02:05.698835', 'ocnli_dev_eval_loss': 3.386833429336548, 'ocnli_dev_eval_acc': 0.375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-8802', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_18-00-42_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-8802', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*许*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 16, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 18:03:29.444173', 'ocnli_dev_eval_loss': 2.321362018585205, 'ocnli_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-27030', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_18-02-07_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-27030', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*，*mask*。*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 17, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 18:04:53.389233', 'ocnli_dev_eval_loss': 2.9849958419799805, 'ocnli_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-12677', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_18-03-31_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-12677', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*者*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 18, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 18:06:16.650251', 'ocnli_dev_eval_loss': 2.1405954360961914, 'ocnli_dev_eval_acc': 0.28125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-8349', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_18-04-55_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-8349', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0**mask*，*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 19, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 18:07:39.431807', 'ocnli_dev_eval_loss': 2.34597110748291, 'ocnli_dev_eval_acc': 0.25, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-14976', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_18-06-18_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-14976', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0**mask*。*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 20, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 18:09:06.014143', 'ocnli_dev_eval_loss': 3.2120938301086426, 'ocnli_dev_eval_acc': 0.28125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-15484', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_18-07-41_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-15484', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*说*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 21, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 18:10:29.700082', 'ocnli_dev_eval_loss': 2.5250606536865234, 'ocnli_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-3565', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_18-09-08_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-3565', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*，*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 22, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 18:11:52.495638', 'ocnli_dev_eval_loss': 3.5915472507476807, 'ocnli_dev_eval_acc': 0.375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-24680', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_18-10-31_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-24680', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*，*mask*许*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 23, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 18:33:26.066025', 'ocnli_dev_eval_loss': 2.1712751388549805, 'ocnli_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_18-31-57_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*的*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 18:34:52.289886', 'ocnli_dev_eval_loss': 2.518157958984375, 'ocnli_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_18-33-28_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*，*mask*说*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 1, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 18:36:19.232086', 'ocnli_dev_eval_loss': 2.481074094772339, 'ocnli_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_18-34-54_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*，*mask*，*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 2, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 18:37:48.401987', 'ocnli_dev_eval_loss': 2.2387781143188477, 'ocnli_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_18-36-21_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*，*mask**+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 3, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 18:39:16.934267', 'ocnli_dev_eval_loss': 2.679225444793701, 'ocnli_dev_eval_acc': 0.3125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_18-37-50_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0**mask*说*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 4, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 18:40:44.986448', 'ocnli_dev_eval_loss': 2.491194009780884, 'ocnli_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_18-39-19_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask**+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 5, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 18:42:11.619383', 'ocnli_dev_eval_loss': 2.6422677040100098, 'ocnli_dev_eval_acc': 0.25, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_18-40-47_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0**mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 6, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 18:43:39.448464', 'ocnli_dev_eval_loss': 1.994215488433838, 'ocnli_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_18-42-14_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 7, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 18:45:04.960577', 'ocnli_dev_eval_loss': 2.2286925315856934, 'ocnli_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_18-43-41_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*，*mask*的*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 8, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 18:46:37.012021', 'ocnli_dev_eval_loss': 3.081838607788086, 'ocnli_dev_eval_acc': 0.34375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_18-45-07_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*也*mask*说*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 9, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 18:48:04.249130', 'ocnli_dev_eval_loss': 2.388972282409668, 'ocnli_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_18-46-39_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*，*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 10, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 18:49:30.642249', 'ocnli_dev_eval_loss': 2.5446839332580566, 'ocnli_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_18-48-06_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*。*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 11, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 18:50:56.991211', 'ocnli_dev_eval_loss': 2.5201075077056885, 'ocnli_dev_eval_acc': 0.25, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_18-49-32_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0**mask*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 12, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 18:52:23.992266', 'ocnli_dev_eval_loss': 2.9628114700317383, 'ocnli_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_18-50-59_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*，*mask*者*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 13, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 18:53:50.336575', 'ocnli_dev_eval_loss': 2.0115785598754883, 'ocnli_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_18-52-26_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*，*mask*让*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 14, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 18:55:19.497442', 'ocnli_dev_eval_loss': 2.4476404190063477, 'ocnli_dev_eval_acc': 0.40625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_18-53-52_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*说*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 15, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 18:56:46.184558', 'ocnli_dev_eval_loss': 3.386833429336548, 'ocnli_dev_eval_acc': 0.375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_18-55-21_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*许*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 16, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 18:58:14.039202', 'ocnli_dev_eval_loss': 2.321362018585205, 'ocnli_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_18-56-48_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*，*mask*。*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 17, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 18:59:39.004375', 'ocnli_dev_eval_loss': 2.9849958419799805, 'ocnli_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_18-58-16_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*者*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 18, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 19:01:05.613517', 'ocnli_dev_eval_loss': 2.1405954360961914, 'ocnli_dev_eval_acc': 0.28125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_18-59-41_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0**mask*，*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 19, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 19:02:31.766011', 'ocnli_dev_eval_loss': 2.34597110748291, 'ocnli_dev_eval_acc': 0.25, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_19-01-07_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0**mask*。*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 20, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 19:04:03.696999', 'ocnli_dev_eval_loss': 3.2120938301086426, 'ocnli_dev_eval_acc': 0.28125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_19-02-34_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*说*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 21, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 19:05:30.500676', 'ocnli_dev_eval_loss': 2.5250606536865234, 'ocnli_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_19-04-05_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*，*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 22, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 19:06:56.922423', 'ocnli_dev_eval_loss': 3.5915472507476807, 'ocnli_dev_eval_acc': 0.375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_19-05-32_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt--13-hfl/chinese-roberta-wwm-ext-18303', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*，*mask*许*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/ocnli/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 23, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 13:15:43.970450', 'ocnli_dev_eval_loss': 2.0806126594543457, 'ocnli_dev_eval_acc': 0.59375, 'ocnli_test_eval_loss': 2.9935834407806396, 'ocnli_test_eval_acc': 0.430952380952381, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-16-13-hfl/chinese-roberta-wwm-ext-5750', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/May24_13-11-42_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-16-13-hfl/chinese-roberta-wwm-ext-5750', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*是*+sentl_1**sep+*', 'mapping': "{'contradiction':'不','neutral':'或','entailment':'是'}", 'template_path': 'my_auto_template/ocnli/16-13.sort.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': '', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 23:14:12.657195', 'tnews_dev_eval_loss': 1.731707215309143, 'tnews_dev_eval_acc': 0.5208333333333334, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-20520', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_23-12-46_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-20520', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 23:15:47.227658', 'tnews_dev_eval_loss': 2.48370099067688, 'tnews_dev_eval_acc': 0.525, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-20520', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_23-14-15_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-20520', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*的*mask**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 1, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 23:17:21.419997', 'tnews_dev_eval_loss': 1.7867538928985596, 'tnews_dev_eval_acc': 0.5083333333333333, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-20520', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_23-15-50_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-20520', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*新*mask**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 2, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 23:20:44.095848', 'tnews_dev_eval_loss': 1.7851245403289795, 'tnews_dev_eval_acc': 0.5041666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_23-19-07_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 23:22:29.854576', 'tnews_dev_eval_loss': 2.895141124725342, 'tnews_dev_eval_acc': 0.5166666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_23-20-47_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*的*mask**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 1, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 23:24:12.731595', 'tnews_dev_eval_loss': 1.766000509262085, 'tnews_dev_eval_acc': 0.5208333333333334, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_23-22-33_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*新*mask**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 2, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 23:25:58.872543', 'tnews_dev_eval_loss': 2.864348888397217, 'tnews_dev_eval_acc': 0.5125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_23-24-16_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*好*mask**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 3, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 23:27:38.325758', 'tnews_dev_eval_loss': 1.7333704233169556, 'tnews_dev_eval_acc': 0.5333333333333333, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_23-26-02_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*（*mask*）*sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 4, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 23:29:25.495086', 'tnews_dev_eval_loss': 3.130199670791626, 'tnews_dev_eval_acc': 0.49583333333333335, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_23-27-41_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*的*mask*。*sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 5, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 23:31:12.014688', 'tnews_dev_eval_loss': 2.4995367527008057, 'tnews_dev_eval_acc': 0.525, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_23-29-28_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*好*mask*。*sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 6, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 23:32:56.968343', 'tnews_dev_eval_loss': 2.867581605911255, 'tnews_dev_eval_acc': 0.5125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_23-31-15_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*好*mask*！*sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 7, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 23:34:36.965113', 'tnews_dev_eval_loss': 1.7553776502609253, 'tnews_dev_eval_acc': 0.5125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_23-33-00_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*新*mask*的*sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 8, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 23:36:20.330371', 'tnews_dev_eval_loss': 3.1356992721557617, 'tnews_dev_eval_acc': 0.5541666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_23-34-40_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*新*mask*：*sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 9, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 23:38:01.467786', 'tnews_dev_eval_loss': 1.766000509262085, 'tnews_dev_eval_acc': 0.5208333333333334, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_23-36-23_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*新*mask**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 10, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 23:39:42.259865', 'tnews_dev_eval_loss': 1.7241499423980713, 'tnews_dev_eval_acc': 0.55, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_23-38-04_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*新*mask*网*sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 11, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 23:41:26.827073', 'tnews_dev_eval_loss': 3.1477715969085693, 'tnews_dev_eval_acc': 0.5125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_23-39-45_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*新*mask*，*sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 12, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 23:43:11.016863', 'tnews_dev_eval_loss': 2.702667713165283, 'tnews_dev_eval_acc': 0.5458333333333333, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_23-41-30_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*中*mask*网*sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 13, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 23:44:51.257268', 'tnews_dev_eval_loss': 1.7375602722167969, 'tnews_dev_eval_acc': 0.5083333333333333, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_23-43-14_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*无*mask**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 14, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 23:46:31.681646', 'tnews_dev_eval_loss': 1.6657062768936157, 'tnews_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_23-44-54_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*(*mask*)*sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 15, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 23:48:20.973063', 'tnews_dev_eval_loss': 2.895141124725342, 'tnews_dev_eval_acc': 0.5166666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_23-46-34_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*的*mask**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 16, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 23:50:03.253122', 'tnews_dev_eval_loss': 1.6222264766693115, 'tnews_dev_eval_acc': 0.5541666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_23-48-24_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*从*mask**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 17, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 23:51:47.452217', 'tnews_dev_eval_loss': 2.7544493675231934, 'tnews_dev_eval_acc': 0.5125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_23-50-06_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*人*sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 18, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 23:53:36.079304', 'tnews_dev_eval_loss': 2.9999992847442627, 'tnews_dev_eval_acc': 0.5083333333333333, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_23-51-50_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*大*mask**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 19, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 23:55:22.216600', 'tnews_dev_eval_loss': 3.0701823234558105, 'tnews_dev_eval_acc': 0.5291666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_23-53-39_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*（*mask**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 20, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 23:57:03.573623', 'tnews_dev_eval_loss': 1.7827305793762207, 'tnews_dev_eval_acc': 0.475, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_23-55-25_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*本*mask**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 21, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-24 23:58:42.916521', 'tnews_dev_eval_loss': 1.7609118223190308, 'tnews_dev_eval_acc': 0.5041666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_23-57-06_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*原*mask**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 22, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-25 00:00:28.742563', 'tnews_dev_eval_loss': 2.8222498893737793, 'tnews_dev_eval_acc': 0.5375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May24_23-58-46_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*小*mask**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 23, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-25 00:02:13.511377', 'tnews_dev_eval_loss': 2.864348888397217, 'tnews_dev_eval_acc': 0.5125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May25_00-00-31_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*好*mask**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 24, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-25 00:03:53.033917', 'tnews_dev_eval_loss': 2.744990587234497, 'tnews_dev_eval_acc': 0.06666666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May25_00-02-16_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**mask*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 25, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-25 00:05:38.436724', 'tnews_dev_eval_loss': 3.137040615081787, 'tnews_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May25_00-03-56_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*新*mask*：*+sent_0**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 26, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-25 00:07:18.553217', 'tnews_dev_eval_loss': 1.806396245956421, 'tnews_dev_eval_acc': 0.5375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May25_00-05-41_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*新*mask*，*+sent_0**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 27, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-25 00:09:02.465961', 'tnews_dev_eval_loss': 2.752351999282837, 'tnews_dev_eval_acc': 0.5666666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May25_00-07-21_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中*mask*：*+sent_0**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 28, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-25 00:10:44.090791', 'tnews_dev_eval_loss': 1.7653414011001587, 'tnews_dev_eval_acc': 0.55, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May25_00-09-05_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*（*mask*）*+sent_0**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 29, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-25 00:12:33.190162', 'tnews_dev_eval_loss': 2.989147901535034, 'tnews_dev_eval_acc': 0.525, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May25_00-10-47_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*新*mask*的*+sent_0**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 30, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-25 00:14:14.488921', 'tnews_dev_eval_loss': 1.7808964252471924, 'tnews_dev_eval_acc': 0.5333333333333333, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May25_00-12-36_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*国*mask*：*+sent_0**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 31, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-25 00:15:56.122813', 'tnews_dev_eval_loss': 1.6945843696594238, 'tnews_dev_eval_acc': 0.5541666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May25_00-14-17_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*：*+sent_0**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 32, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-25 00:17:36.611029', 'tnews_dev_eval_loss': 1.7648707628250122, 'tnews_dev_eval_acc': 0.5666666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May25_00-15-59_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*小*mask*：*+sent_0**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 33, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-25 00:19:16.718739', 'tnews_dev_eval_loss': 1.8353055715560913, 'tnews_dev_eval_acc': 0.5083333333333333, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May25_00-17-39_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中*mask*，*+sent_0**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 34, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-25 00:20:57.103551', 'tnews_dev_eval_loss': 1.7928377389907837, 'tnews_dev_eval_acc': 0.5416666666666666, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May25_00-19-19_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*好*mask*：*+sent_0**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 35, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-25 00:22:40.077293', 'tnews_dev_eval_loss': 2.933032274246216, 'tnews_dev_eval_acc': 0.5333333333333333, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May25_00-21-00_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*新*mask**+sent_0**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 36, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-25 00:24:20.102693', 'tnews_dev_eval_loss': 1.7041168212890625, 'tnews_dev_eval_acc': 0.5375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May25_00-22-43_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*好*mask*，*+sent_0**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 37, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-25 00:26:01.879726', 'tnews_dev_eval_loss': 1.64993417263031, 'tnews_dev_eval_acc': 0.5291666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May25_00-24-23_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*。*+sent_0**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 38, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-25 00:27:42.506608', 'tnews_dev_eval_loss': 1.6727797985076904, 'tnews_dev_eval_acc': 0.575, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May25_00-26-05_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**mask*：*+sent_0**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 39, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-25 00:29:22.315670', 'tnews_dev_eval_loss': 1.7117316722869873, 'tnews_dev_eval_acc': 0.55, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May25_00-27-45_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*(*mask*)*+sent_0**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 40, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-25 00:31:06.914483', 'tnews_dev_eval_loss': 2.837054967880249, 'tnews_dev_eval_acc': 0.55, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May25_00-29-25_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*民*+sent_0**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 41, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-25 00:32:50.627375', 'tnews_dev_eval_loss': 3.2245802879333496, 'tnews_dev_eval_acc': 0.5375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May25_00-31-10_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*好*mask*！*+sent_0**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 42, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-25 00:34:29.482741', 'tnews_dev_eval_loss': 1.7553400993347168, 'tnews_dev_eval_acc': 0.55, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May25_00-32-53_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*小*mask*，*+sent_0**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 43, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-25 00:36:17.107779', 'tnews_dev_eval_loss': 2.8201115131378174, 'tnews_dev_eval_acc': 0.5333333333333333, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May25_00-34-32_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**mask*。*+sent_0**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 44, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-25 00:37:55.906487', 'tnews_dev_eval_loss': 1.7536593675613403, 'tnews_dev_eval_acc': 0.5166666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May25_00-36-20_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*的*+sent_0**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 45, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-25 00:39:34.965396', 'tnews_dev_eval_loss': 1.7571148872375488, 'tnews_dev_eval_acc': 0.5541666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May25_00-37-59_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*【*mask*】*+sent_0**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 46, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-25 00:41:13.808762', 'tnews_dev_eval_loss': 1.6912287473678589, 'tnews_dev_eval_acc': 0.5291666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May25_00-39-38_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*，*+sent_0**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 47, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-25 00:42:53.260330', 'tnews_dev_eval_loss': 1.6625397205352783, 'tnews_dev_eval_acc': 0.5458333333333333, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May25_00-41-17_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*！*+sent_0**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 48, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-25 00:44:34.864442', 'tnews_dev_eval_loss': 1.8292343616485596, 'tnews_dev_eval_acc': 0.5208333333333334, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May25_00-42-56_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt--13-hfl/chinese-roberta-wwm-ext-4576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 260, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中*mask**+sent_0**sep+*', 'mapping': "{100: '事', 101: '文', 102: '娱', 103: '体', 104: '财', 106: '房', 107: '车', 108: '教', 109: '科', 110: '军', 112: '旅', 113: '国', 114: '股', 115: '农', 116: '游'}", 'template_path': 'my_auto_template/tnews/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 49, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-25 09:36:16.586997', 'tnews_dev_eval_loss': 3.830787181854248, 'tnews_dev_eval_acc': 0.575, 'tnews_test_eval_loss': 3.612119197845459, 'tnews_test_eval_acc': 0.564179104477612, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-16-13-hfl/chinese-roberta-wwm-ext-20613', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/May25_09-31-28_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-16-13-hfl/chinese-roberta-wwm-ext-20613', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'tnews', 'data_dir': 'data/k-shot/tnews/16-13', 'max_seq_length': 270, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*新*mask*网*sep+*', 'mapping': "{100:'事',101:'文',102:'娱',103:'体',104:'财',106:'房',107:'车',108:'教',109:'科',110:'军',112:'旅',113:'国',114:'股',115:'农',116:'游'}", 'template_path': 'my_auto_template/tnews/16-13.sort.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': '', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-26 23:48:59.550953', 'bustm_dev_eval_loss': 0.8478603959083557, 'bustm_dev_eval_acc': 0.78125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May26_23-46-02_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask**+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-26 23:52:06.538261', 'bustm_dev_eval_loss': 1.1917839050292969, 'bustm_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May26_23-49-02_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask**+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 1, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-26 23:55:12.554140', 'bustm_dev_eval_loss': 1.297044277191162, 'bustm_dev_eval_acc': 0.78125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May26_23-52-09_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask**+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 2, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-26 23:58:20.385005', 'bustm_dev_eval_loss': 2.1624655723571777, 'bustm_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May26_23-55-15_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*？*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 3, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 00:01:29.745292', 'bustm_dev_eval_loss': 1.3394742012023926, 'bustm_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May26_23-58-22_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*，*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 4, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 00:04:34.894495', 'bustm_dev_eval_loss': 2.2231602668762207, 'bustm_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May27_00-01-32_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*？*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 5, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 00:07:41.561083', 'bustm_dev_eval_loss': 1.2511541843414307, 'bustm_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May27_00-04-37_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*。*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 6, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 00:10:45.840020', 'bustm_dev_eval_loss': 2.2560222148895264, 'bustm_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May27_00-07-44_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*不*mask*？*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 7, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 00:13:56.288745', 'bustm_dev_eval_loss': 1.8497920036315918, 'bustm_dev_eval_acc': 0.71875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May27_00-10-48_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*。*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 8, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 00:16:59.212418', 'bustm_dev_eval_loss': 1.554986834526062, 'bustm_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May27_00-13-59_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*，*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 9, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 00:20:07.267484', 'bustm_dev_eval_loss': 2.3597359657287598, 'bustm_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May27_00-17-01_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*？*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 10, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 00:23:19.153158', 'bustm_dev_eval_loss': 2.514073133468628, 'bustm_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May27_00-20-09_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*，*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 11, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 00:26:23.549040', 'bustm_dev_eval_loss': 2.2875254154205322, 'bustm_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May27_00-23-21_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*你*mask*？*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 12, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 00:29:29.349752', 'bustm_dev_eval_loss': 0.8478603959083557, 'bustm_dev_eval_acc': 0.78125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May27_00-26-26_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask**+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 13, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 00:32:36.961988', 'bustm_dev_eval_loss': 1.1917839050292969, 'bustm_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May27_00-29-32_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask**+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 14, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 00:35:41.729663', 'bustm_dev_eval_loss': 1.7057459354400635, 'bustm_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May27_00-32-39_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*了*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 15, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 00:38:50.901707', 'bustm_dev_eval_loss': 2.6224374771118164, 'bustm_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May27_00-35-44_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*。*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 16, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 00:41:53.783716', 'bustm_dev_eval_loss': 1.845443844795227, 'bustm_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May27_00-38-53_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*说*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 17, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 00:44:55.377093', 'bustm_dev_eval_loss': 1.8004037141799927, 'bustm_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May27_00-41-56_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0**mask*？*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 18, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 00:47:57.543388', 'bustm_dev_eval_loss': 1.8227882385253906, 'bustm_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May27_00-44-58_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*说*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 19, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 00:50:59.680657', 'bustm_dev_eval_loss': 1.1551814079284668, 'bustm_dev_eval_acc': 0.6875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May27_00-48-00_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*你*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 20, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 00:54:07.380131', 'bustm_dev_eval_loss': 1.297044277191162, 'bustm_dev_eval_acc': 0.78125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May27_00-51-02_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask**+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 21, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 00:57:18.939576', 'bustm_dev_eval_loss': 2.780597686767578, 'bustm_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May27_00-54-09_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*是*mask*？*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 22, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 01:00:22.163060', 'bustm_dev_eval_loss': 2.1820807456970215, 'bustm_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May27_00-57-21_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*但*mask*？*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 23, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 01:03:26.330586', 'bustm_dev_eval_loss': 2.2671337127685547, 'bustm_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May27_01-00-24_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*?*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 24, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 01:06:31.874784', 'bustm_dev_eval_loss': 1.2562841176986694, 'bustm_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May27_01-03-28_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*！*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 25, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 01:09:35.828518', 'bustm_dev_eval_loss': 1.7656739950180054, 'bustm_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May27_01-06-34_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*?*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 26, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 01:12:38.754137', 'bustm_dev_eval_loss': 2.1624655723571777, 'bustm_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May27_01-09-38_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*？*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 27, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 01:15:47.508149', 'bustm_dev_eval_loss': 1.3394742012023926, 'bustm_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May27_01-12-41_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*，*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 28, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 01:18:52.255187', 'bustm_dev_eval_loss': 1.2511541843414307, 'bustm_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May27_01-15-50_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*。*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 29, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 01:21:57.336450', 'bustm_dev_eval_loss': 2.2231602668762207, 'bustm_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May27_01-18-54_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*？*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 30, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 01:25:01.820511', 'bustm_dev_eval_loss': 2.2560222148895264, 'bustm_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May27_01-22-00_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*不*mask*？*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 31, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 01:28:12.689941', 'bustm_dev_eval_loss': 1.8497920036315918, 'bustm_dev_eval_acc': 0.71875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May27_01-25-04_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*。*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 32, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 01:31:19.056545', 'bustm_dev_eval_loss': 1.554986834526062, 'bustm_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May27_01-28-15_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*，*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 33, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 01:34:26.207156', 'bustm_dev_eval_loss': 2.3597359657287598, 'bustm_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May27_01-31-21_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*？*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 34, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 01:37:31.599226', 'bustm_dev_eval_loss': 2.514073133468628, 'bustm_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May27_01-34-28_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*，*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 35, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 01:40:36.087387', 'bustm_dev_eval_loss': 2.1624655723571777, 'bustm_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May27_01-37-34_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*？*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 36, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 01:43:40.713831', 'bustm_dev_eval_loss': 0.8478603959083557, 'bustm_dev_eval_acc': 0.78125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May27_01-40-38_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask**+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 37, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 01:46:50.924010', 'bustm_dev_eval_loss': 1.3394742012023926, 'bustm_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May27_01-43-43_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*，*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 38, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 01:50:00.908695', 'bustm_dev_eval_loss': 1.2511541843414307, 'bustm_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May27_01-46-53_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*。*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 39, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 01:53:07.041334', 'bustm_dev_eval_loss': 2.2231602668762207, 'bustm_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May27_01-50-03_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*？*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 40, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 01:56:18.891304', 'bustm_dev_eval_loss': 1.3394742012023926, 'bustm_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May27_01-53-09_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*，*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 41, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 01:59:22.765607', 'bustm_dev_eval_loss': 1.554986834526062, 'bustm_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May27_01-56-21_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*，*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 42, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 02:02:27.949195', 'bustm_dev_eval_loss': 2.514073133468628, 'bustm_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May27_01-59-25_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*，*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 43, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 02:05:33.762647', 'bustm_dev_eval_loss': 2.1624655723571777, 'bustm_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May27_02-02-30_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*？*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 44, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 02:08:43.495567', 'bustm_dev_eval_loss': 1.1917839050292969, 'bustm_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May27_02-05-36_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask**+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 45, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 02:11:46.914723', 'bustm_dev_eval_loss': 1.2511541843414307, 'bustm_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May27_02-08-46_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*。*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 46, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 02:14:53.743363', 'bustm_dev_eval_loss': 0.8478603959083557, 'bustm_dev_eval_acc': 0.78125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May27_02-11-49_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask**+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 47, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 02:17:58.354039', 'bustm_dev_eval_loss': 2.1624655723571777, 'bustm_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/May27_02-14-56_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt--13-hfl/chinese-roberta-wwm-ext-32706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*？*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 48, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-05-27 09:29:41.669252', 'bustm_dev_eval_loss': 0.8820634484291077, 'bustm_dev_eval_acc': 0.78125, 'bustm_test_eval_loss': 1.7008596658706665, 'bustm_test_eval_acc': 0.5406320541760722, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-16-13-hfl/chinese-roberta-wwm-ext-19350', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/May27_09-20-50_livingskytech7', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-16-13-hfl/chinese-roberta-wwm-ext-19350', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'bustm', 'data_dir': 'data/k-shot/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask**+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/bustm/16-13.sort.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': '', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
